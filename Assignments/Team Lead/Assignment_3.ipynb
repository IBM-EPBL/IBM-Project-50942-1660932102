{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment - 3\n",
        "\n",
        "Problem Statement : Build CNN Model for Classification Of Flowers"
      ],
      "metadata": {
        "id": "Ao6fJPh6nF06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the drive"
      ],
      "metadata": {
        "id": "LwlTcw9X8EOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EiHEsIygfDf",
        "outputId": "5de6af3b-beec-4d6f-d192-4619b02dc413"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd/content/drive/MyDrive/IBM-Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgZFs9wegV5Z",
        "outputId": "8696faa7-0abf-456d-87bc-27f7281d0470"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IBM-Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9PFkbph_BtR",
        "outputId": "9d40312f-972b-4fb7-f8d2-082f2e4871fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mflowers\u001b[0m/  Flowers-Dataset.zip  flowers.h5  \u001b[01;34moutput\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Unzipping the dataset"
      ],
      "metadata": {
        "id": "0hPxL3C0mZ9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip Flowers-Dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr5qIbWdmQ4R",
        "outputId": "89412ee1-9d59-43fd-e4d8-e751205487c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Flowers-Dataset.zip\n",
            "  inflating: flowers/daisy/100080576_f52e8ee070_n.jpg  \n",
            "replace flowers/daisy/10140303196_b88d3d6cec.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Image Augmentation"
      ],
      "metadata": {
        "id": "A7LnKQC7nMLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "TpAleIL3mfhS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,zoom_range =0.2,horizontal_flip=True,vertical_flip = False)"
      ],
      "metadata": {
        "id": "gWBbxQx2nVxX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator ( rescale = 1. / 255 )"
      ],
      "metadata": {
        "id": "qEbUpa1dnZp2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting data into Train, Validation and Test folders"
      ],
      "metadata": {
        "id": "qDzNAyTq96z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install split-folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/content/drive/MyDrive/IBM-Project/flowers', output=\"output\", seed=1337, ratio=(.8, 0.1,0.1)) "
      ],
      "metadata": {
        "id": "pWQiAUAi95v1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41471dd-0e6a-4c17-8b5e-3019ce0e27ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 4317 files [01:12, 59.16 files/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_datagen.flow_from_directory(r\"/content/drive/MyDrive/IBM-Project/output/train\",target_size =(64,64),class_mode ='categorical',batch_size=24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1FdGPYSndQ_",
        "outputId": "6c8ee96a-7a60-4363-e26b-4969becf129a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3452 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XunloXODnilv",
        "outputId": "5dda6623-988f-4d15-bb8d-9b0a9e441c61"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtest = test_datagen.flow_from_directory('/content/drive/MyDrive/IBM-Project/output/test',\n",
        "                                         target_size=(64,64),\n",
        "                                         class_mode='categorical',\n",
        "                                         batch_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7BQ6yq9nrph",
        "outputId": "842f31ab-7476-45ff-d502-0bd24d1e33c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 435 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Create Model"
      ],
      "metadata": {
        "id": "zSSS6ntGoGlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
      ],
      "metadata": {
        "id": "pSPku1fOnzys"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential() #Initializing sequential model"
      ],
      "metadata": {
        "id": "i10REzlZoLXu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Adding layers"
      ],
      "metadata": {
        "id": "8DC3E0JYoOiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))  #Convolution layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))  #MaxPooling layer\n",
        "model.add(Flatten())  #Flatten layer\n",
        "model.add(Dense(300,activation='relu'))  #Hidden layer 1\n",
        "model.add(Dense(150,activation='relu'))  #Hidden layer 2\n",
        "model.add(Dense(75,activation='relu')) #Hidden layer 3\n",
        "model.add(Dense(5,activation='softmax')) #Output layer"
      ],
      "metadata": {
        "id": "jz-KMgLyoQUW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Compile the Model"
      ],
      "metadata": {
        "id": "1SMDhb3joZjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkk4L3EtoWMe",
        "outputId": "8f7ccede-c417-4807-987a-5b77fb77210d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 30752)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 300)               9225900   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 150)               45150     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 75)                11325     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5)                 380       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,283,651\n",
            "Trainable params: 9,283,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Fit The Model"
      ],
      "metadata": {
        "id": "o0crf69QogLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "XX505O_KofDA"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the validation data"
      ],
      "metadata": {
        "id": "mocmI9PSAhMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid = train_datagen.flow_from_directory(r\"/content/drive/MyDrive/IBM-Project/output/val\",target_size =(64,64),class_mode ='categorical',batch_size=24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlOzM-oUAUNj",
        "outputId": "67aa0a09-ea4e-4fac-d6ad-9b35bebb28a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 430 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
        "                        patience=5)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                        patience=5,\n",
        "                        factor=0.5,min_lr=0.00001)\n",
        "\n",
        "callback = [reduce_lr,early_stopping]"
      ],
      "metadata": {
        "id": "RcoTNoihomWN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,\n",
        "                    steps_per_epoch=len(x_train),\n",
        "                    epochs=30,\n",
        "                    callbacks=callback,\n",
        "                    validation_data=x_valid,\n",
        "                    validation_steps=len(x_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfiToyCloo29",
        "outputId": "cdff388d-722c-4d0f-dcff-59ec64a8e547"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "144/144 [==============================] - 25s 167ms/step - loss: 1.3190 - accuracy: 0.4409 - val_loss: 1.1465 - val_accuracy: 0.5349 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "144/144 [==============================] - 23s 162ms/step - loss: 1.1008 - accuracy: 0.5623 - val_loss: 1.0215 - val_accuracy: 0.6140 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "144/144 [==============================] - 23s 162ms/step - loss: 1.0005 - accuracy: 0.5994 - val_loss: 0.9714 - val_accuracy: 0.6186 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.9235 - accuracy: 0.6359 - val_loss: 0.9658 - val_accuracy: 0.6116 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "144/144 [==============================] - 23s 162ms/step - loss: 0.8563 - accuracy: 0.6712 - val_loss: 0.9994 - val_accuracy: 0.6233 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.8051 - accuracy: 0.6868 - val_loss: 0.9353 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "144/144 [==============================] - 25s 174ms/step - loss: 0.7861 - accuracy: 0.6926 - val_loss: 0.9103 - val_accuracy: 0.6767 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.7361 - accuracy: 0.7219 - val_loss: 0.9894 - val_accuracy: 0.6512 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "144/144 [==============================] - 23s 159ms/step - loss: 0.6942 - accuracy: 0.7344 - val_loss: 0.9609 - val_accuracy: 0.6395 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "144/144 [==============================] - 24s 166ms/step - loss: 0.6472 - accuracy: 0.7500 - val_loss: 0.9056 - val_accuracy: 0.6698 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "144/144 [==============================] - 23s 157ms/step - loss: 0.6027 - accuracy: 0.7764 - val_loss: 0.9223 - val_accuracy: 0.6791 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "144/144 [==============================] - 23s 157ms/step - loss: 0.5772 - accuracy: 0.7781 - val_loss: 0.9574 - val_accuracy: 0.6698 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.5426 - accuracy: 0.8010 - val_loss: 0.8990 - val_accuracy: 0.6837 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "144/144 [==============================] - 24s 167ms/step - loss: 0.4974 - accuracy: 0.8137 - val_loss: 0.9658 - val_accuracy: 0.6721 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.4695 - accuracy: 0.8224 - val_loss: 1.1658 - val_accuracy: 0.6302 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.4427 - accuracy: 0.8392 - val_loss: 0.9754 - val_accuracy: 0.7000 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "144/144 [==============================] - 23s 160ms/step - loss: 0.3858 - accuracy: 0.8615 - val_loss: 1.1605 - val_accuracy: 0.6698 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.3803 - accuracy: 0.8676 - val_loss: 0.9830 - val_accuracy: 0.6721 - lr: 0.0010\n",
            "Epoch 19/30\n",
            "144/144 [==============================] - 23s 157ms/step - loss: 0.3558 - accuracy: 0.8702 - val_loss: 1.0639 - val_accuracy: 0.6744 - lr: 0.0010\n",
            "Epoch 20/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.3434 - accuracy: 0.8740 - val_loss: 1.1546 - val_accuracy: 0.6488 - lr: 0.0010\n",
            "Epoch 21/30\n",
            "144/144 [==============================] - 23s 158ms/step - loss: 0.3053 - accuracy: 0.8885 - val_loss: 1.1736 - val_accuracy: 0.6581 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fee41e69d50>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Save the Model"
      ],
      "metadata": {
        "id": "QEPRBRjRxsgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('flowers.h5')"
      ],
      "metadata": {
        "id": "0d9jq1g1osED"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Test the Model"
      ],
      "metadata": {
        "id": "84OYw-uZx2GA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "img=image.load_img('/content/drive/MyDrive/IBM-Project/output/test/dandelion/138166590_47c6cb9dd0.jpg',target_size=(64,64))\n",
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "pred=np.argmax(model.predict(x))\n",
        "op=['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nX7TMkB-x1bq",
        "outputId": "a068349e-e7d2-4d54-dae2-bab2505264aa"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dandelion'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=image.load_img('/content/drive/MyDrive/IBM-Project/output/test/sunflower/10541580714_ff6b171abd_n.jpg',target_size=(64,64))\n",
        "x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "pred=np.argmax(model.predict(x))\n",
        "op=['daisy','dandelion','rose','sunflower','tulip']\n",
        "op[pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fko4EVmQx-W1",
        "outputId": "3ae2d6e0-3c53-4c30-8bd1-21bfd5e6ec64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sunflower'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = model.evaluate_generator(xtest, len(xtest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOoSTkoPVSBf",
        "outputId": "c4153189-4a73-4bc1-8de0-36aed4f9e37f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Error: {a[0]}')\n",
        "print(f'Accuracy: {a[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdrOenmcVnHP",
        "outputId": "b9ef7d5c-b06b-40b8-f576-93a7ef6d70d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 1.6151995658874512\n",
            "Accuracy: 0.6206896305084229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kifq8yWYVwqz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}